{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfchHAPeoUXO",
        "outputId": "76ae8b31-35d7-4437-f6ba-f27dc84e505c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/libtpu-releases/index.html\n",
            "Requirement already satisfied: torch_xla[tpu] in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from torch_xla[tpu]) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_xla[tpu]) (2.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from torch_xla[tpu]) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_xla[tpu]) (2.32.4)\n",
            "Collecting libtpu==0.0.21 (from torch_xla[tpu])\n",
            "  Downloading libtpu-0.0.21-cp312-cp312-manylinux_2_31_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: tpu-info in /usr/local/lib/python3.12/dist-packages (from torch_xla[tpu]) (0.2.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_xla[tpu]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_xla[tpu]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_xla[tpu]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_xla[tpu]) (2026.1.4)\n",
            "Requirement already satisfied: grpcio>=1.65.5 in /usr/local/lib/python3.12/dist-packages (from tpu-info->torch_xla[tpu]) (1.76.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from tpu-info->torch_xla[tpu]) (6.33.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from tpu-info->torch_xla[tpu]) (14.3.2)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.65.5->tpu-info->torch_xla[tpu]) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->tpu-info->torch_xla[tpu]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->tpu-info->torch_xla[tpu]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->tpu-info->torch_xla[tpu]) (0.1.2)\n",
            "Downloading libtpu-0.0.21-cp312-cp312-manylinux_2_31_x86_64.whl (149.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.8/149.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libtpu\n",
            "  Attempting uninstall: libtpu\n",
            "    Found existing installation: libtpu 0.0.17\n",
            "    Uninstalling libtpu-0.0.17:\n",
            "      Successfully uninstalled libtpu-0.0.17\n",
            "Successfully installed libtpu-0.0.21\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_xla.core.xla_model as xm\n",
        "import numpy as np\n",
        "import time\n",
        "import csv\n",
        "from pathlib import Path\n",
        "import torch_xla\n",
        "\n",
        "# =========================\n",
        "# Configuration\n",
        "# =========================\n",
        "\n",
        "device = torch_xla.device()\n",
        "\n",
        "SIZES = {\n",
        "    \"S\": 1024,\n",
        "    \"M\": 4096,\n",
        "    \"L\": 8192,\n",
        "}\n",
        "\n",
        "WARMUP = 10\n",
        "ITERS = 50\n",
        "DTYPE = torch.float32\n",
        "\n",
        "POWER_W = {\n",
        "    \"tpu\": 75,  # estimation TPU v2/v3\n",
        "}\n",
        "\n",
        "RESULTS_DIR = Path(\"results\")\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "CSV_PATH = RESULTS_DIR / \"matmul_tpu.csv\"\n",
        "\n",
        "device = xm.xla_device()\n",
        "\n",
        "# =========================\n",
        "# Stats utils\n",
        "# =========================\n",
        "\n",
        "def compute_stats(times_ms):\n",
        "    t = np.array(times_ms)\n",
        "    return {\n",
        "        \"mean_ms\": t.mean(),\n",
        "        \"p50_ms\": np.percentile(t, 50),\n",
        "        \"p95_ms\": np.percentile(t, 95),\n",
        "    }\n",
        "\n",
        "def gflops(n, ms):\n",
        "    flops = 2 * (n ** 3)\n",
        "    return flops / (ms / 1000) / 1e9\n",
        "\n",
        "def energy_j(power, ms):\n",
        "    return power * (ms / 1000)\n",
        "\n",
        "# =========================\n",
        "# Benchmark TPU\n",
        "# =========================\n",
        "\n",
        "def bench_tpu(n):\n",
        "    x = torch.rand((n, n), dtype=DTYPE, device=device)\n",
        "    y = torch.rand((n, n), dtype=DTYPE, device=device)\n",
        "\n",
        "    # Warmup\n",
        "    for _ in range(WARMUP):\n",
        "        out = torch.mm(x, y)\n",
        "        torch_xla.sync()\n",
        "        _ = out.cpu()\n",
        "\n",
        "    times = []\n",
        "\n",
        "    for _ in range(ITERS):\n",
        "        start = time.perf_counter()\n",
        "\n",
        "        out = torch.mm(x, y)\n",
        "        torch_xla.sync()\n",
        "        _ = out.cpu()   # vraie synchronisation\n",
        "\n",
        "        end = time.perf_counter()\n",
        "        times.append((end - start) * 1000)\n",
        "\n",
        "    stats = compute_stats(times)\n",
        "    stats[\"gflops\"] = gflops(n, stats[\"mean_ms\"])\n",
        "    stats[\"energy_j\"] = energy_j(POWER_W[\"tpu\"], stats[\"mean_ms\"])\n",
        "\n",
        "    return stats\n",
        "\n",
        "# =========================\n",
        "# CSV save\n",
        "# =========================\n",
        "\n",
        "def save_row(size_tag, n, stats):\n",
        "    exists = CSV_PATH.exists()\n",
        "\n",
        "    with open(CSV_PATH, \"a\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "\n",
        "        if not exists:\n",
        "            w.writerow([\n",
        "                \"device\", \"size\", \"N\",\n",
        "                \"mean_ms\", \"p50_ms\", \"p95_ms\",\n",
        "                \"gflops\", \"power_w\", \"energy_j\"\n",
        "            ])\n",
        "\n",
        "        w.writerow([\n",
        "            \"tpu\", size_tag, n,\n",
        "            stats[\"mean_ms\"], stats[\"p50_ms\"], stats[\"p95_ms\"],\n",
        "            stats[\"gflops\"], POWER_W[\"tpu\"], stats[\"energy_j\"]\n",
        "        ])\n",
        "\n",
        "# =========================\n",
        "# Main\n",
        "# =========================\n",
        "\n",
        "def main():\n",
        "    print(\"TPU device:\", device)\n",
        "\n",
        "    for tag, n in SIZES.items():\n",
        "        print(f\"\\n=== Size {tag} (N={n}) ===\")\n",
        "\n",
        "        stats = bench_tpu(n)\n",
        "        print(\"TPU:\", stats)\n",
        "\n",
        "        save_row(tag, n, stats)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1UxoorroeAg",
        "outputId": "467ad93f-b3b7-46dd-e004-9d4f0ade5b99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2005435833.py:33: DeprecationWarning: Use torch_xla.device instead\n",
            "  device = xm.xla_device()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU device: xla:0\n",
            "\n",
            "=== Size S (N=1024) ===\n",
            "TPU: {'mean_ms': np.float64(4.672073459992134), 'p50_ms': np.float64(1.6427794999458456), 'p95_ms': np.float64(3.5857449499417244), 'gflops': np.float64(459.6425262550592), 'energy_j': np.float64(0.3504055094994101)}\n",
            "\n",
            "=== Size M (N=4096) ===\n",
            "TPU: {'mean_ms': np.float64(47.449615139996695), 'p50_ms': np.float64(47.59982199999513), 'p95_ms': np.float64(57.0689740500427), 'gflops': np.float64(2896.5240933250184), 'energy_j': np.float64(3.558721135499752)}\n",
            "\n",
            "=== Size L (N=8192) ===\n",
            "TPU: {'mean_ms': np.float64(153.16001115998915), 'p50_ms': np.float64(148.08910250002327), 'p95_ms': np.float64(177.71413344995608), 'gflops': np.float64(7178.842698225342), 'energy_j': np.float64(11.487000836999187)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_xla\n",
        "import numpy as np\n",
        "import time\n",
        "import csv\n",
        "from pathlib import Path\n",
        "\n",
        "# =========================\n",
        "# Configuration\n",
        "# =========================\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 64\n",
        "WARMUP = 10\n",
        "ITERS = 50\n",
        "DTYPE = torch.float32\n",
        "\n",
        "POWER_W = {\"tpu\": 75}\n",
        "\n",
        "RESULTS_DIR = Path(\"results\")\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "CSV_PATH = RESULTS_DIR / \"cnn_tpu.csv\"\n",
        "\n",
        "device = torch_xla.device()\n",
        "\n",
        "# =========================\n",
        "# CNN\n",
        "# =========================\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * (IMAGE_SIZE // 4) ** 2, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.features(x))\n",
        "\n",
        "# =========================\n",
        "# Stats\n",
        "# =========================\n",
        "\n",
        "def compute_stats(times):\n",
        "    t = np.array(times)\n",
        "    return {\n",
        "        \"mean_ms\": float(t.mean()),\n",
        "        \"p50_ms\": float(np.percentile(t, 50)),\n",
        "        \"p95_ms\": float(np.percentile(t, 95)),\n",
        "    }\n",
        "\n",
        "def energy_j(power, ms):\n",
        "    return power * (ms / 1000)\n",
        "\n",
        "# =========================\n",
        "# Benchmark TPU\n",
        "# =========================\n",
        "\n",
        "def bench_tpu():\n",
        "\n",
        "    model = SimpleCNN().to(device)\n",
        "    model.eval()\n",
        "\n",
        "    x = torch.rand(\n",
        "        (BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE),\n",
        "        dtype=DTYPE,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Warmup\n",
        "    with torch.no_grad():\n",
        "        for _ in range(WARMUP):\n",
        "            out = model(x)\n",
        "            torch_xla.sync()\n",
        "            _ = out.cpu()\n",
        "\n",
        "    times = []\n",
        "\n",
        "    # Benchmark\n",
        "    with torch.no_grad():\n",
        "        for _ in range(ITERS):\n",
        "\n",
        "            start = time.perf_counter()\n",
        "\n",
        "            out = model(x)\n",
        "            torch_xla.sync()\n",
        "            _ = out.cpu()\n",
        "\n",
        "            end = time.perf_counter()\n",
        "            times.append((end - start) * 1000)\n",
        "\n",
        "    stats = compute_stats(times)\n",
        "    stats[\"energy_j\"] = energy_j(POWER_W[\"tpu\"], stats[\"mean_ms\"])\n",
        "\n",
        "    return stats\n",
        "\n",
        "# =========================\n",
        "# CSV save\n",
        "# =========================\n",
        "\n",
        "def save_row(stats):\n",
        "\n",
        "    exists = CSV_PATH.exists()\n",
        "\n",
        "    with open(CSV_PATH, \"a\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "\n",
        "        if not exists:\n",
        "            w.writerow([\n",
        "                \"device\",\n",
        "                \"mean_ms\", \"p50_ms\", \"p95_ms\",\n",
        "                \"energy_j\"\n",
        "            ])\n",
        "\n",
        "        w.writerow([\n",
        "            \"tpu\",\n",
        "            stats[\"mean_ms\"],\n",
        "            stats[\"p50_ms\"],\n",
        "            stats[\"p95_ms\"],\n",
        "            stats[\"energy_j\"],\n",
        "        ])\n",
        "\n",
        "# =========================\n",
        "# Main\n",
        "# =========================\n",
        "\n",
        "def main():\n",
        "\n",
        "    print(\"=== CNN TPU Benchmark ===\")\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    stats = bench_tpu()\n",
        "\n",
        "    print(\"TPU:\", stats)\n",
        "    save_row(stats)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YxsDUdZpnDw",
        "outputId": "bf77c15f-c55c-4640-8f59-209ecb7a0a29"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CNN TPU Benchmark ===\n",
            "Device: xla:0\n",
            "TPU: {'mean_ms': 0.8080623200021364, 'p50_ms': 0.7848949999242905, 'p95_ms': 0.9801534999269278, 'energy_j': 0.06060467400016022}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# TPU support (optional)\n",
        "try:\n",
        "    import torch_xla\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    TPU_AVAILABLE = True\n",
        "except:\n",
        "    TPU_AVAILABLE = False\n",
        "\n",
        "# =========================\n",
        "# CONFIG — tune to stress hardware\n",
        "# =========================\n",
        "\n",
        "BATCH_SIZE = 128      # increase to stress more\n",
        "IMAGE_SIZE = 224\n",
        "WARMUP = 10\n",
        "ITERS = 50\n",
        "DTYPE = torch.float32\n",
        "\n",
        "# =========================\n",
        "# Device selection\n",
        "# =========================\n",
        "\n",
        "if TPU_AVAILABLE:\n",
        "    device = torch_xla.device()\n",
        "    device_type = \"TPU\"\n",
        "elif torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    device_type = \"GPU\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    device_type = \"CPU\"\n",
        "\n",
        "print(\"Running on:\", device_type)\n",
        "\n",
        "# =========================\n",
        "# Model\n",
        "# =========================\n",
        "\n",
        "model = models.resnet50(weights=None).to(device)\n",
        "model.eval()\n",
        "\n",
        "# heavy input tensor\n",
        "x_cpu = torch.rand(\n",
        "    (BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE),\n",
        "    dtype=DTYPE\n",
        ")\n",
        "\n",
        "if device_type == \"GPU\":\n",
        "    x = x_cpu.pin_memory().to(device, non_blocking=True)\n",
        "elif device_type == \"TPU\":\n",
        "    x = x_cpu.to(device)\n",
        "else:\n",
        "    x = x_cpu\n",
        "\n",
        "# =========================\n",
        "# Sync helpers\n",
        "# =========================\n",
        "\n",
        "def sync(out=None):\n",
        "    if device_type == \"GPU\":\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "    elif device_type == \"TPU\":\n",
        "        torch_xla.sync()\n",
        "        if out is not None:\n",
        "            _ = out.cpu()\n",
        "\n",
        "# =========================\n",
        "# Warmup\n",
        "# =========================\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(WARMUP):\n",
        "        out = model(x)\n",
        "        sync(out)\n",
        "\n",
        "# =========================\n",
        "# Benchmark loop\n",
        "# =========================\n",
        "\n",
        "times = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(ITERS):\n",
        "\n",
        "        start = time.perf_counter()\n",
        "\n",
        "        out = model(x)\n",
        "        sync(out)\n",
        "\n",
        "        end = time.perf_counter()\n",
        "        times.append(end - start)\n",
        "\n",
        "# =========================\n",
        "# Results\n",
        "# =========================\n",
        "\n",
        "times = np.array(times)\n",
        "\n",
        "latency_ms = times.mean() * 1000\n",
        "throughput = BATCH_SIZE / times.mean()\n",
        "\n",
        "print(\"\\n=== STRESS RESULTS ===\")\n",
        "print(f\"Mean latency: {latency_ms:.2f} ms / batch\")\n",
        "print(f\"Throughput:   {throughput:.0f} images/sec\")\n",
        "print(f\"P95 latency:  {np.percentile(times,95)*1000:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-Bhp8xbqWbX",
        "outputId": "2c80d938-7828-423e-f9cb-067fd8e10070"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on: TPU\n",
            "\n",
            "=== STRESS RESULTS ===\n",
            "Mean latency: 23.03 ms / batch\n",
            "Throughput:   5559 images/sec\n",
            "P95 latency:  23.36 ms\n"
          ]
        }
      ]
    }
  ]
}