# üìà Analyse d√©taill√©e des r√©sultats bruts ‚Äî CPU vs GPU

Cette section pr√©sente une analyse approfondie des mesures obtenues lors des benchmarks CPU et GPU. L‚Äôobjectif est de comprendre **le comportement r√©el des architectures** face √† diff√©rents workloads, et d‚Äôidentifier les facteurs qui influencent les performances et l‚Äôefficacit√© √©nerg√©tique.

Les tests couvrent principalement :

- des multiplications matricielles de tailles croissantes,
- des inf√©rences de r√©seaux convolutionnels,
- une d√©composition du temps GPU (transferts m√©moire vs calcul).

---

## üî¨ Analyse ‚Äî Multiplication matricielle (MatMul)

La multiplication matricielle est un workload fortement intensif en calcul, typique des applications scientifiques et d‚Äôintelligence artificielle. Elle permet d‚Äôobserver la mont√©e en charge des architectures.

### ‚ûú Petites matrices

Pour les tailles r√©duites :

- le CPU reste comp√©titif,
- le GPU apporte un gain limit√©.

L‚Äôexplication principale r√©side dans le co√ªt des transferts m√©moire CPU ‚Üí GPU ‚Üí CPU. Le GPU doit d‚Äôabord recevoir les donn√©es avant de pouvoir calculer, ce qui introduit une latence fixe non n√©gligeable.

Dans ce r√©gime :

- le calcul est rapide,
- mais les transferts dominent le temps total.

üëâ Le GPU est sous-exploit√© car l‚Äôintensit√© de calcul ne compense pas l‚Äôoverhead m√©moire.

---

### ‚ûú Tailles interm√©diaires

Lorsque la taille des matrices augmente :

- le temps de calcul devient pr√©dominant,
- le parall√©lisme GPU commence √† √™tre pleinement exploit√©.

Le GPU montre alors une acc√©l√©ration nette par rapport au CPU, car :

- il ex√©cute massivement des op√©rations en parall√®le,
- sa bande passante m√©moire interne est √©lev√©e.

On observe une transition vers un r√©gime **compute-bound** (limit√© par le calcul plut√¥t que par les transferts).

---

### ‚ûú Grandes matrices

Pour les tailles importantes :

- le GPU atteint son r√©gime optimal,
- le CPU montre une saturation progressive.

Le GPU devient largement dominant gr√¢ce √† :

- son architecture massivement parall√®le,
- ses unit√©s sp√©cialis√©es pour les op√©rations matricielles.

M√™me si les transferts m√©moire restent pr√©sents, ils repr√©sentent une part relative plus faible du temps total.

üëâ Le gain de performance devient significatif et stable.

---

## ‚öô Analyse ‚Äî R√©seaux neuronaux convolutionnels (CNN)

Les CNN repr√©sentent un workload r√©aliste pour l‚ÄôIA moderne :

- calcul parall√®le massif,
- forte localit√© m√©moire,
- op√©rations r√©p√©titives.

Les mesures montrent :

- une latence GPU nettement inf√©rieure,
- un d√©bit largement sup√©rieur.

M√™me avec le co√ªt des transferts m√©moire, le calcul GPU domine rapidement.

Cela s‚Äôexplique par :

- l‚Äôoptimisation mat√©rielle des convolutions,
- la forte parall√©lisation des couches,
- la r√©utilisation efficace des donn√©es en m√©moire.

üëâ Les CNN exploitent naturellement les avantages du GPU.

---

## üîÑ D√©composition du temps GPU

Le temps GPU total se d√©compose en :

```
Temps total = H2D + Compute + D2H
```

o√π :

- **H2D** : transfert CPU ‚Üí GPU  
- **Compute** : calcul r√©el GPU  
- **D2H** : transfert GPU ‚Üí CPU  

### Observations

- petites charges ‚Üí transferts dominants  
- grandes charges ‚Üí calcul dominant  

Cette √©volution montre que le GPU devient r√©ellement efficace lorsque le co√ªt fixe des transferts est amorti par une charge de calcul importante.

üëâ Cela met en √©vidence un principe cl√© :

> plus l‚Äôintensit√© de calcul est √©lev√©e, plus le GPU est rentable.

---

## üîã Analyse √©nerg√©tique

L‚Äô√©nergie estim√©e suit la relation :

```
√ânergie = Puissance √ó Temps
```

M√™me si le GPU consomme plus de puissance instantan√©e :

- il termine les calculs beaucoup plus rapidement,
- l‚Äô√©nergie totale consomm√©e est souvent inf√©rieure.

Cela indique que :

- l‚Äôacc√©l√©ration mat√©rielle peut r√©duire le co√ªt √©nerg√©tique global,
- la rapidit√© d‚Äôex√©cution est un facteur cl√© d‚Äôefficacit√© √©nerg√©tique.

---

# üìä Analyse sp√©cifique ‚Äî CNN ResNet50 (CPU vs CUDA)

Les mesures suivantes ont √©t√© obtenues lors du benchmark d‚Äôinf√©rence de ResNet50 avec un batch size de 256 :

### R√©sultats bruts

| Device | Mean Latency | P95 Latency | Throughput |
|--------|--------------|------------|------------|
| CPU    | 15 789.59 ms | 18 360.40 ms | 16 img/s |
| CUDA   | 477.01 ms    | 477.37 ms   | 537 img/s |

---

## ‚è± Analyse de la latence

### üîπ CPU

- Latence moyenne : **~15.8 secondes**
- P95 : **~18.4 secondes**

L‚Äô√©cart significatif entre la moyenne et le P95 (~2.6 secondes) indique une variabilit√© notable.  
Cela peut s‚Äôexpliquer par :

- la contention CPU,
- la gestion m√©moire,
- l‚Äôabsence de parall√©lisme massif.

Le CPU ex√©cute les convolutions de mani√®re beaucoup plus s√©quentielle compar√© au GPU.

---

### üîπ GPU (CUDA)

- Latence moyenne : **~477 ms**
- P95 : **~477 ms**

La moyenne et le P95 sont presque identiques.

üëâ Cela indique une **ex√©cution extr√™mement stable**.  
Le GPU maintient une performance constante sur les it√©rations.

La latence est environ :

```
15 789 ms / 477 ms ‚âà 33x plus rapide
```

Le GPU offre donc une acc√©l√©ration d‚Äôenviron **33√ó** sur ce workload.

---

## üöÄ Analyse du throughput

### CPU

- **16 images par seconde**

Cela correspond √† un traitement relativement lent pour un batch de 256 images.

---

### GPU

- **537 images par seconde**

Le GPU traite plus d‚Äôun demi-millier d‚Äôimages par seconde, ce qui montre :

- une exploitation efficace du parall√©lisme,
- une excellente optimisation des convolutions,
- une bande passante m√©moire √©lev√©e.

---

## üìà Facteur d‚Äôacc√©l√©ration global

Le gain de performance est spectaculaire :

| M√©trique | Acc√©l√©ration GPU |
|----------|------------------|
| Latence  | ~33√ó plus rapide |
| Throughput | ~33√ó plus √©lev√© |

Cette coh√©rence confirme que le GPU est en r√©gime pleinement **compute-bound**, o√π le calcul domine largement les co√ªts de transfert m√©moire.

---

## üî¨ Interpr√©tation architecturale

ResNet50 est compos√© principalement de :

- convolutions 2D,
- op√©rations matricielles massives,
- normalisations batch,
- activations non lin√©aires.

Ces op√©rations :

- sont hautement parall√©lisables,
- correspondent exactement aux unit√©s sp√©cialis√©es du GPU,
- exploitent efficacement la m√©moire interne rapide.

Le CPU, bien que performant en g√©n√©raliste, ne dispose pas :

- d‚Äôun nombre suffisant d‚Äôunit√©s parall√®les,
- d‚Äôune architecture optimis√©e pour ce type de workload massif.

---

## üîã Implication √©nerg√©tique

M√™me si le GPU consomme plus de puissance instantan√©e :

- il termine le calcul 33 fois plus vite,
- l‚Äô√©nergie totale consomm√©e est probablement inf√©rieure.

Cela sugg√®re une **meilleure efficacit√© √©nerg√©tique globale du GPU pour l‚Äôinf√©rence CNN √† grande √©chelle**.

---

## üéØ Conclusion sp√©cifique ResNet50

Les r√©sultats d√©montrent clairement que :

- Le CPU n‚Äôest pas adapt√© √† l‚Äôinf√©rence CNN batch intensive.
- Le GPU exploite pleinement le parall√©lisme du mod√®le.
- L‚Äô√©cart devient massif d√®s que la charge de calcul est importante.

Ce benchmark confirme que pour des workloads deep learning r√©alistes :

> le GPU n‚Äôapporte pas une simple am√©lioration marginale,  
> mais un changement d‚Äôordre de grandeur en performance.

---


## üìä Tendances g√©n√©rales observ√©es

Les r√©sultats mettent en √©vidence plusieurs r√©gimes :

### Workloads l√©gers

- overhead m√©moire dominant
- avantage CPU possible

### Workloads interm√©diaires

- acc√©l√©ration GPU progressive
- meilleur ratio calcul/transfert

### Workloads intensifs

- GPU pleinement exploit√©
- gains majeurs en temps et √©nergie

---

## üéØ Implications pratiques

Ces observations permettent de d√©gager plusieurs recommandations :

### CPU adapt√© pour

- petites t√¢ches,
- traitements s√©quentiels,
- op√©rations √† faible parall√©lisme.

### GPU adapt√© pour

- calcul scientifique,
- deep learning,
- traitement batch,
- multiplication matricielle massive.

Le facteur d√©terminant reste **l‚Äôintensit√© de calcul par rapport aux transferts m√©moire**.

---

## üß† Conclusion de l‚Äôanalyse brute

Les r√©sultats confirment un principe fondamental de l‚Äôacc√©l√©ration mat√©rielle :

> le GPU excelle lorsque le calcul massif amortit les co√ªts de transfert.

Cette √©tude montre que le choix CPU/GPU ne d√©pend pas uniquement de la puissance brute, mais de la nature du workload, de la taille des donn√©es et du rapport calcul/m√©moire.

Les benchmarks illustrent clairement :

- la transition d‚Äôun r√©gime limit√© par les transferts vers un r√©gime domin√© par le calcul,
- l‚Äôimportance de structurer les pipelines pour exploiter efficacement le GPU,
- le potentiel √©nerg√©tique des architectures acc√©l√©r√©es.

Ces conclusions servent de base pour optimiser les strat√©gies de calcul dans des contextes r√©els.
