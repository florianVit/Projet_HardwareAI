# üìà Analyse d√©taill√©e des r√©sultats bruts ‚Äî CPU vs GPU

Cette section pr√©sente une analyse approfondie des mesures obtenues lors des benchmarks CPU et GPU. L‚Äôobjectif est de comprendre **le comportement r√©el des architectures** face √† diff√©rents workloads, et d‚Äôidentifier les facteurs qui influencent les performances et l‚Äôefficacit√© √©nerg√©tique.

Les tests couvrent principalement :

- des multiplications matricielles de tailles croissantes,
- des inf√©rences de r√©seaux convolutionnels,
- une d√©composition du temps GPU (transferts m√©moire vs calcul).

---

## üî¨ Analyse ‚Äî Multiplication matricielle (MatMul)

La multiplication matricielle est un workload fortement intensif en calcul, typique des applications scientifiques et d‚Äôintelligence artificielle. Elle permet d‚Äôobserver la mont√©e en charge des architectures.

### ‚ûú Petites matrices

Pour les tailles r√©duites :

- le CPU reste comp√©titif,
- le GPU apporte un gain limit√©.

L‚Äôexplication principale r√©side dans le co√ªt des transferts m√©moire CPU ‚Üí GPU ‚Üí CPU. Le GPU doit d‚Äôabord recevoir les donn√©es avant de pouvoir calculer, ce qui introduit une latence fixe non n√©gligeable.

Dans ce r√©gime :

- le calcul est rapide,
- mais les transferts dominent le temps total.

üëâ Le GPU est sous-exploit√© car l‚Äôintensit√© de calcul ne compense pas l‚Äôoverhead m√©moire.

---

### ‚ûú Tailles interm√©diaires

Lorsque la taille des matrices augmente :

- le temps de calcul devient pr√©dominant,
- le parall√©lisme GPU commence √† √™tre pleinement exploit√©.

Le GPU montre alors une acc√©l√©ration nette par rapport au CPU, car :

- il ex√©cute massivement des op√©rations en parall√®le,
- sa bande passante m√©moire interne est √©lev√©e.

On observe une transition vers un r√©gime **compute-bound** (limit√© par le calcul plut√¥t que par les transferts).

---

### ‚ûú Grandes matrices

Pour les tailles importantes :

- le GPU atteint son r√©gime optimal,
- le CPU montre une saturation progressive.

Le GPU devient largement dominant gr√¢ce √† :

- son architecture massivement parall√®le,
- ses unit√©s sp√©cialis√©es pour les op√©rations matricielles.

M√™me si les transferts m√©moire restent pr√©sents, ils repr√©sentent une part relative plus faible du temps total.

üëâ Le gain de performance devient significatif et stable.

---

## ‚öô Analyse ‚Äî R√©seaux neuronaux convolutionnels (CNN)

Les CNN repr√©sentent un workload r√©aliste pour l‚ÄôIA moderne :

- calcul parall√®le massif,
- forte localit√© m√©moire,
- op√©rations r√©p√©titives.

Les mesures montrent :

- une latence GPU nettement inf√©rieure,
- un d√©bit largement sup√©rieur.

M√™me avec le co√ªt des transferts m√©moire, le calcul GPU domine rapidement.

Cela s‚Äôexplique par :

- l‚Äôoptimisation mat√©rielle des convolutions,
- la forte parall√©lisation des couches,
- la r√©utilisation efficace des donn√©es en m√©moire.

üëâ Les CNN exploitent naturellement les avantages du GPU.

---

## üîÑ D√©composition du temps GPU

Le temps GPU total se d√©compose en :

```
Temps total = H2D + Compute + D2H
```

o√π :

- **H2D** : transfert CPU ‚Üí GPU  
- **Compute** : calcul r√©el GPU  
- **D2H** : transfert GPU ‚Üí CPU  

### Observations

- petites charges ‚Üí transferts dominants  
- grandes charges ‚Üí calcul dominant  

Cette √©volution montre que le GPU devient r√©ellement efficace lorsque le co√ªt fixe des transferts est amorti par une charge de calcul importante.

üëâ Cela met en √©vidence un principe cl√© :

> plus l‚Äôintensit√© de calcul est √©lev√©e, plus le GPU est rentable.

---

## üîã Analyse √©nerg√©tique

L‚Äô√©nergie estim√©e suit la relation :

```
√ânergie = Puissance √ó Temps
```

M√™me si le GPU consomme plus de puissance instantan√©e :

- il termine les calculs beaucoup plus rapidement,
- l‚Äô√©nergie totale consomm√©e est souvent inf√©rieure.

Cela indique que :

- l‚Äôacc√©l√©ration mat√©rielle peut r√©duire le co√ªt √©nerg√©tique global,
- la rapidit√© d‚Äôex√©cution est un facteur cl√© d‚Äôefficacit√© √©nerg√©tique.

---

## üìä Tendances g√©n√©rales observ√©es

Les r√©sultats mettent en √©vidence plusieurs r√©gimes :

### Workloads l√©gers

- overhead m√©moire dominant
- avantage CPU possible

### Workloads interm√©diaires

- acc√©l√©ration GPU progressive
- meilleur ratio calcul/transfert

### Workloads intensifs

- GPU pleinement exploit√©
- gains majeurs en temps et √©nergie

---

## üéØ Implications pratiques

Ces observations permettent de d√©gager plusieurs recommandations :

### CPU adapt√© pour

- petites t√¢ches,
- traitements s√©quentiels,
- op√©rations √† faible parall√©lisme.

### GPU adapt√© pour

- calcul scientifique,
- deep learning,
- traitement batch,
- multiplication matricielle massive.

Le facteur d√©terminant reste **l‚Äôintensit√© de calcul par rapport aux transferts m√©moire**.

---

## üß† Conclusion de l‚Äôanalyse brute

Les r√©sultats confirment un principe fondamental de l‚Äôacc√©l√©ration mat√©rielle :

> le GPU excelle lorsque le calcul massif amortit les co√ªts de transfert.

Cette √©tude montre que le choix CPU/GPU ne d√©pend pas uniquement de la puissance brute, mais de la nature du workload, de la taille des donn√©es et du rapport calcul/m√©moire.

Les benchmarks illustrent clairement :

- la transition d‚Äôun r√©gime limit√© par les transferts vers un r√©gime domin√© par le calcul,
- l‚Äôimportance de structurer les pipelines pour exploiter efficacement le GPU,
- le potentiel √©nerg√©tique des architectures acc√©l√©r√©es.

Ces conclusions servent de base pour optimiser les strat√©gies de calcul dans des contextes r√©els.
